<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Full Report</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="
        fivegoldstars.github.io/assets/css/main.css
      " />
		<noscript><link rel="stylesheet" href="fivegoldstars.github.io/assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1>Full Report</h1>
						<p>How We Did It</p>
					</header>
				
				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="/">Back to Home</a></li>
							<li><a href="#context">Overview</a></li>
							<li><a href="#intro">The Project</a></li>
                            <li><a href="#review">Literature Review</a></li>
							<li><a href="#methods">Methodology</a></li>
							<li><a href="#data">Datasets</a></li>
                             <li><a href="#polar">Polar Chart</a></li>
                            <li><a href="#descr">Descriptive Analysis</a></li>
                            <li><a href="#statsan">Statistical Analysis</a></li>
                            <li><a href="#results">Results</a></li>
                            <li><a href="#limits">Limitations</a></li>
                            <li><a href="#ref">References</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

                        <!-- Context -->
                        
                        <section id="context" class="main">
                                <h2><b>Why this Project?</b></h2>
								<h3><b><u>Who cares about ratings?</u></b></h3>
                            
                            <p>As globalisation results in greater competition amongst products and services and our world becomes increasingly reliant on technology, society has put more and more faith in ratings' abilities to guide our decisions. With websites such as Amazon, Trivago or CompareTheMarket allowing consumers to compare everything from makeup to travel insurance, consumers are easily able to consult peer-reviews and ratings to help them make informed purchases. Applications such as GoogleLens even allow users to view 'reviews, address details and opening times' (Hall & Boyle, 2019) for restaurants at a glance or look up 'reviews of movie DVDs on your entertainment stand,' making it easier than ever to simplify the entire consumer experience into numbers and 'stars'.</p>
                            
                            <p>Recently, the concept of ratings has expanded beyond the marketplace and entered the social realm. Apps like <em>Peeple</em> (<a href="https://www.forthepeeple.com/">1, </a><a href="https://itunes.apple.com/us/app/peeple/id1008896593?mt=8">2</a>)  allow users to ‘rate other human beings’ (McCarthy, 2016) according to their professional abilities, personal characteristics and dating life. Many have drawn parallels between Peeple and the 'Nosedive' episode of Black Mirror where people are given a numeric rating based on their 'interactions with other people' (Connick, 2018). In 2016 when the episode first aired this seemed like nothing more than a dystopian reality, but <a href="https://www.businessinsider.com/china-social-credit-system-punishments-and-rewards-explained-2018-4?r=UK&IR=T">China's New Social Credit System</a>coming into play in 2020 - a system that sees citizens rewarded for good deeds that provide access to 'cheaper public transport and shorter waits at hospitals' (Connick, 2018) and low scores resulting in 'slower internet speed' and 'restricted access to hotels' - this dystopia is incredibly close to being realised. 
</p>
                                
                                <p>Then, considering ratings are gradually dictating countless aspects of our lives, it seems natural to question exactly how good ratings are at indicating the quality or success of a product. This is what this research project aims to explore through looking at ratings in the context of films and box office success. By analysing the correlation between film ratings and their revenue, we hope to discern whether or not ratings are a good indicator of film success. We hope our results can serve as a starting point to investigate whether our findings are applicable to other domains (e.g. hotel ratings). 
 </p>
                            
								<h3><b><u>For and Against Ratings</u></b></h3>
								<p>Although the above paragraphs have evidenced the increasing presence of ratings in our lives, they are not necessarily a dominant variable when predicting film success. Although society is subconsciously becoming increasingly dependent on rating systems, films are simultaneously becoming increasingly differentiated to suit specific target audiences. This is just one example of an external factor that may influence box office success. 
                                    
                            <p>For example, recent films have begun to incorporate cultural identity into their plot as a way of challenging white dominance in Hollywood (e.g. <em>Black Panther</em>, <em>Crazy Rich Asians</em>). These films received a large amount of media attention with successful openings, their success accredit to their ability to draw from 'culturally specific experiences' (Buckle, 2018) and gain 'major community support'.  By creating films that feature 'cultural-specific montages' (Gray, 2019) and are 'fundamentally about identity', their high box office revenue may be due to their narrative and cultural contexts as well as their ability to appeal to a globalised audience. 

                                        
                                        <p>Variables such as genre (popularity of action films over documentaries) or even production studio (Marvel vs. DC) may be more indicative of success. For example, Marvel films receive ‘the most favorable reviews’ (Brueggemann, 2017) with a ‘small edge in overall popular appeal’, resulting in a larger revenue for the production studio. For these reasons, we have chosen to compare the correlation between ratings and revenue with other variables such as percentage male/female cast and genre. This should hopefully allow us to determine not only whether ratings are able to predict success, but also to what extent they are a contributing factor of success.
</p>
    
							</section>
                                
                                <!-- Introduction -->
							<section id="intro" class="main">
								<h2><b>The Project</b></h2>
                                <h3><b><u>Research Question</u></b></h3>
                                <p>Given the context described above and having decided to focus on film revenue, we generated the following question: <b>Can we trust public film ratings to predict how successful a film will be in the box office?</b>
                                </p>
                                
                                <h3><b><u>Aims</u></b></h3>
                                <p>Our project aims to examine various factors to determine the key variable in predicting box-office success.</p>
                                <p>The main goals for our project are to:</p>
                                <p><ul>
                                    <li> determine whether film ratings influence film revenued</li>
                                    <li> determine whether the gender of actors or film budget is more predictive of box-office success.</li>
                                </ul>
                                
                                <h3><b><u>Hypotheses</u></b></h3>
                                <p>The results we as a group expect to find from our analysis are:
                                <p><ul>
                                    <li> film ratings will not predict box-office success
.</li>
                                    <li>the gender of actors will predict box-office success</li>
                                <li>film budget will predict box-office success</li>
                                </ul>
                        </section>
                        
                        <section id="review" class="main">
                                <h2><b>Literature Review</b></h2>
                            
                            <p>Many studies have looked into both the various factors contributing to a film's box office success (including those mentioned in the previous section) and also the effect that ratings and reviews have on consumer behaviour and revenue. 
                                
                                <p>Literature concerning the effect of reviews can be split into two categories: the effect of official reviews (given by professional critics) and amateur reviews (those of an average moviegoer). Research shows that although critical reviews do have some influence on gross earnings (King, 2007), they instead perform more as predictors of performance instead of having an effect on box office performance. Critics do not serve as opinion leaders for mainstream audiences and are instead indicators of public opinion, with the correlation between critical reviews and cumulative box office takings not conclusive (Eliashberg & Shugan, 1997). Research does to some extent indicate that the possible effects critical reviews have on box office success only occur after a certain amount of time as the majority of tickets are purchased after reviews have been published (King, 2007) resulting in a statistically insignificant relationship between critical reviews and box office revenues (Eliashberg & Shugan, 1997). These findings suggest that although critical reviews are not a reliable way of predicting film success, they instead serve as a way of polarising films into either a 'good' or 'bad' category that has some correlation with a film's box office revenue. 

</p>
                            
                            <p>This lack of strong correlation between ratings may be because critics have a limited impact on consumer behaviour (Austin, 1983), especially as Austin found that consumers have a tendency to evaluate films more positively than critics. As audience opinion differs from critical reviews, critics have no impact on public ticket sales. Contrastingly, research by Berg and Raddick (2016) found little correlation between IMDb user ratings and box office revenue, invalidating this is as reason for insignificant correlation between critical reviews and box office sales. Instead, it may suggest that ratings as a whole (both critical and audience) are a poor indicator of box office success. Our analysis may validate these findings as we are looking at TMDb ratings instead of IMDb ratings, giving more credibility to the claim that ratings are not a reliable predictor of box office success. 

                                
                                <p>However, a study in Russia (Gaenssle et al., 2018) found that audience ratings have a significantly positive influence on box office revenue, with Brewer and Jozefowics (2009) echoing that good reviews from public audiences result in higher gross revenue. Although these findings contradict those in the previous paragraph, this discrepancy may be explained by looking at IMDb's way of aggregating user ratings. IMDb does not display average rating, but instead a weighted average to 'eliminate and reduce attempts at vote stuffing' (Help.imdb.com, n.d.). Whilst their exact formula to calculate weighted average is not publicly available, they seem to place emphasis on users who frequently rate films and value their rating more. In addition, only those registered to IMDB are allowed to rate films. IMDb ratings are then not completely representative of audience ratings, and are instead more reflective of critical ratings (or at least reflective of users with a tendency to engage with films on a deeper level through frequently rating films). Therefore, Berg and Raddick's (2016) conclusion that audience reviews do not predict box office may not be entirely true as their data still concerns critical reviews as opposed to 'layperson' reviews. If this is the case, our use of data from TMDb should show different results as its main purpose is a recommender system so should feature ratings from a more mainstream audience. However, there is still a possibility of 'critical' ratings skewing our findings. Therefore, there is no way for us to truly discern between critical and public opinion in our analysis, but it is an interesting factor to consider. </p>
                            
                            
<p>One of the other factors that has been used to predict film success is budget, with big budgets seemingly indicating high revenues and large box office success (Gaenssle et. al, 2018, Ravid, 1999). Basuroy et al. (2003) describe this relationship in further detail, concluding that large budgets help improve the box office revenue of films with mainly negative reviews with diminished effect on films with positive reviews. These findings indicate that Basuroy et al. do perceive negative ratings have some effect on box office success, effects which can be negated by a high production budget. Brewer and Jozefowicz (2009) also conclude that both production budget and good ratings have statistically significant effects on revenue. To what extent this is true can also be validated by our statistical analysis, comparing the correlation between ratings and revenue as well as budget and revenue. 
</p>
                            
                            <p>Variables that have also been attributed to influencing box office success are: the popularity of the cast and presence of 'stars' (Collins et al., 2002); the familiarity of the film genre such as adventure or action (Desai & Basuroy, 2005, Brewer & Jozefowicz, 2009); the time of release such as releasing films during the Christmas period (Brewer & Jozefowicz, 2009); a films ability to differentiate itself to meet consumer demand such as Crazy Rich Asians (Smith and Smith, 1986); or even search query patterns on Google (Google, 2013). Whilst interesting, these variables are not something our project can investigate in depth with the data from our chosen dataset. They are perhaps other factors that may explain our results, and will be looked at to some extent in our polar chart, but these variables are interesting springboards for further research into this area.  
</p>
                            
                            
                        </section>
                        
                         <!-- Methodology -->
						
						<section id="methods" class="main">
								
                            <h2><b>Methodology</b></h2>
                            
                            <div id="toc_container">
<ul class="toc_list">
    <p class="toc_title">This section describes the research and presentation methods we used. The next paragraphs outline:</p>
    <li><a href="#visualisations">how we created our visualisations</a></li>
 <li><a href="#statsmethods">how we conducted our statistical analysis</a></li>
    <li><a href="#website">how we created our website</a></li>
</ul>
</div>
								
                            
                             <p>We measured the following film-features and contrasted them against film-revenue in turn:
                                <ul>
                            <li> film ratings
</li>
                            <li>film budget</li>
                            <li>film gender split</li>
                            </ul>

                            <section id="visualisations"><p><br><Br></p></section>
                            
                            <h3><b><u>How we created our visualisations</u></b></h3>
                            
                            <p>We created 3 sets of visualisations for each variable: bar-graphs, violin graphs and scatter plots.
</p>
                            
                            <p>Scatter plots were chosen as we could code a line of best fit which would show us if we should expect a positive or negative correlation between variables (or any relationship at all). They would also show us the density of the data i.e. if films were concentrated around a particular film rating. Bar-graphs were chosen as they show the distribution of data. The quantity of our data meant data points greatly overlapped in the scatter plots so having bar-graphs allowed us to categorise the data e.g. by rounding the budget, which in turn showed the separated distributions and frequencies more clearly. We also used violin plots due to their ability to demonstrate the frequency distribution within variable categories rather than the frequency overall e.g. the distribution of film revenues within films which have 80% male actors. Finally, we created histograms to uncover whether our data was skewed. This in turn affected our statistical analysis as we realised our data was non-parametric  and we therefore had to carry-out different statistical tests than we had originally planned. 
</p>
                            
                            <p>All these visualisations were created using Python Azure Notebooks and the Python library Seaborn.</p>
                            
                            <p>We also created one larger polar scatter chart to allow for a visualisation that showed our complete dataset, allowing us an initial insight into the data in an interactive way.</p>
                            
                            <h4><b><em>Bar-Graphs</em></b></h4>
                            
                            <p>We constructed bar-graphs because they are easy for readers to interpret. At a glance, the reader can see a large quantity of data and the changes between categories e.g. between film ratings. We also included additional bars to show the interquartile ranges.

 </p>
                             <p>We chose bar-graphs over line graphs due to the volume of data which made individual lines in the line-graphs difficult to see. Instead, we placed our data into categories which suits bar-graphs better.


</p>
                            
                            <div style=" font-size:80%; text-align:center; width: 100%;"><img src="http://fivegoldstars.github.io/images/Screenshot%202019-01-14%20at%2016.19.05.png"   style="padding-bottom:0.5em; max-width: 100%"  /></div>
                            
                           <div style=" font-size:80%; text-align:center; width:100%"><img src="http://fivegoldstars.github.io/images/Screenshot%202019-01-14%20at%2016.19.13.png"  style="padding-bottom:0.5em; max-height=450px"  /></div>
                            
                            <h4><b><em>Violin Graphs</em></b></h4>
                            
                            <p>We built violin graphs because, like bar-graphs, they are simple for readers to understand. Violin graphs display categorised data e.g. our weighted film ratings and also reveal more information than bar-graphs by presenting the probability density of variables e.g. how values within categories are distributed.

</p>
                            
                            
                            <div style=" font-size:80%; text-align:center; max-width: 100%"><img src="http://fivegoldstars.github.io/images/violingraphcode.png"   style="padding-bottom:0.5em; max-height:250px; max-width: 100%; "  /></div>
                            
                           <div style=" font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/violingraphexample2.png"  max-height: 350px  style="padding-bottom:0.5em; max-width: 100%; max-height: 450px"  /></div>
                            
                            <h4><b><em><br>Scatter Plots</em></b></h4>
                            
                            <p>We coded scatter plots to see any initial correlations between budget / film gender-split / film rating and film revenue. We included a line of best fit to determine potential relationships between factors before undertaking the statistical analysis.

Scatter plots also showed us between which variables films were most concentrated./p>
                            
                            
                            <div style=" font-size:80%; text-align:center; max-width: 100%"><img src="http://fivegoldstars.github.io/images/scattercode.png"  height: 250px  style="padding-bottom:0.5em; max-width: 100%; max-height: 250px"  /></div>
                            
                           <div style=" font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/scattergraph.png"  max-height: 350px  style="padding-bottom:0.5em;"  /></div>
                            
                            <h4><b><em><br>Histograms</em></b></h4>
                            
                            <p>We also plotted histograms for our descriptive analysis to understand the the skewness of the data which in turn informed our statistical analysis.</p>
                            
                             <div style=" font-size:80%; text-align:center; max-width: 100%"><img src="http://fivegoldstars.github.io/images/histcode.png"  height: 250px  style="padding-bottom:0.5em; max-width: 100%; max-height: 250px"  /></div>
                            
                           <div style=" font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/histex.png"  max-height: 350px  style="padding-bottom:0.5em;"  /></div>
                                
                            
                            <h4><b><em><br>Polar Chart</em></b></h4>
                            
                            <p>Our polar chart shows the distribution of films according to different film ratings with the colours representing different genres, the size of the points representing different budgets and the radius representing revenue.This will be looked at in greater detail in the Polar Chart section.</p>
                            
                               <section id="website"><p><br><Br></p></section>
                        
                            
                            <h3><b><u>How we created our website</u></b></h3>
                            
                            <p>Our website was built using a skeleton theme obtained from <a href="https://html5up.net/">HTML5 UP</a>. We chose Github as the hosting platform due to its ability to share files easily through a common repository, as well as the ability to upload Python workbooks to demonstrate our methods in greater detail. Using HTML to create our website (using the IDE Brackets) allowed for more flexibility in the layout of our site, although any changes had to be pushed to the repository causing a slight delay in comparison to the instant changes seen with platforms such as WIX. The ability to embed visualisations such as our Polar Chart with great ease was also an advantage to using Github over other platforms. </p>
                        
                                                    <section id="statsmethods"><p><br><Br></p></section>
                            
                            
                <p><h3><b><u>What statistical analysis methods we used</u></b></h3>

<p><h4><b>Spearman's Rank and Kendall's Tau</b></h4>

<p>We used Python to find the Spearman’s rank and Kendall’s tau correlation coefficients. This assigns a numerical value to the correlation and explains how strong/weak it is. From this information we will also know whether to accept or reject our hypotheses.
</p>

<p>Spearman’s rank is a non-parametric statistical test and is used instead of Pearson’s product-moment correlation when data is not normally distributed. It is used to determine the strength of a monotonic relationship (either when the value of one variable increases, so does the value of the other; or when the value of one variable increases, the other decreases) (Laerd Statistics, 2018).
</p>

<div style=" font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/spearman-1-small.png"  height="height" style="padding-bottom:0.5em;" id="figure-extra-large" /><br><em>Figure A: example of monotonic and non-monotonic relationships</em></div>

<p>Coefficient values will be between -1 and +1. +1 denotes a perfect positive correlation, -1 denotes a perfect negative correlation and 0 denotes no correlation at all. It is calculated using the following equation:</p>

<div style=" font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/Figure%208.5.png"  max-width: 250px height="height" style="padding-bottom:0.5em;" id="figure-small" /><br><em>In the equation <b>d</b> is the difference between ranks and <b>n</b> is the number of ranks</em></div>


<p><br>Kendall’s tau is a non-parametric test similar to Spearman’s Rank. It is used when many scores have the same rank e.g. for our film ratings (Field, 2005).</p>

<p><b><h4>Spearman's Rank vs. Kendall's Tau</b></h4></p>

<p>Interpretations of the two tests are very similar but Spearman’s is more widely used. Kendall’s tau p-value is more accurate if there is a smaller sample size which is why we also calculated Spearman’s rank. However, there is evidence to suggest that Kendall’s tau is a better estimate of correlation than Spearman’s rank(Field, 2005). Kendall’s tau is also much less sensitive to error. Furthermore, Kendall’s tau is calculated based on comparing pairs of data points and seeing if they ‘match’, whereas Spearman’s rank is based on deviations (Statistics Solutions, 2018).</p>

<p>For our project we therefore chose to use both given that for some variables, many scores had the same rank but for others they did not. Using both tests will also pick up differences in accuracies between the two and strengthen overlaps in results.
    
                             
                        
                        </section>
                            
                            
                            <section id="data" class="main">
								<h2><b>Datasets</b></h2>
                                
<div id="toc_container">
<ul class="toc_list">
    <li><a href="#source"> The source of our data </a></li>
    <li><a href="#reliability"> Reliability</a></li>
    <li><a href="#cleaning">What we did </a></li>
    <li><a href="#ethics">Ethics </a></li>
 
</div>
                                
                                <section id="source" class="main"><br><br></section>
                                
                                <h3><b><u>The source of our data</h3></u></b>
    
    <p>Our data came from <a href="https://www.kaggle.com/"><em>Kaggle</em></a>, a platform where users can upload datasets for other users to download and analyse. Our specific dataset can be found here a href="https://www.kaggle.com/rounakbanik/the-movies-dataset/home"><em>The Movies Dataset</em></a>.  </p>
                            
                            <p>We chose this to be the source of our data as not only did it contain the information we required for our analysis (movie budget, revenue, credits) but it was in a machine readible format (.csv) making it perfect for immediate use. The file contained metadata for the 45,000 movies listed on <a href="movielens.org"><em>MovieLens,</em></a> with ratings being recorded from <a href="themoviedb.org"><em>TMDb.</em></a> 
                                
                                <p>The dataset collected data through using the <em>TMDb</em> Open API whereas the ratings were compiled from the <em>MovieLens</em> datset found <a href="https://grouplens.org/datasets/movielens/latest/">here.</a> The fact that these two sources of data had already been cohesively compiled meant that less time needed to be spent gathering data and could instead be used for analysis.</p>
                            
                            <p>This dataset also gave us a large initial amount of data to work with (although the number of movies was narrowed it down through selective filtering processes described later) which would allow our analysis to hopefully be more reflective of the entire film industry as we were unable to obtain data for every film produced. 
                            
                            </p>
                                
                                 <section id="reliability" class="main"><br><br></section>
                                
                                <h3><b><u>Reliability</h3></u></b>
                            
                            <p>The reliability of the data is somewhat unclear. Whislt the dataset itself obtains data from two established websites, both of these websites are built on user-input.</p>
                            
                            <p><em>TMDb</em> is a 'community built' (TMDb, n.d.) database, with every piece of data available having been contributed by a user. Although the site is facilitated by staff moderators and recommendations are given for where to obtain information such as film revenue or budget, there is no way for us to validate all 45,000 entries. Instead, we must put trust in TMDb's authentication process. This also means that not every film has a complete set of metadata as shown during our cleaning process, narrowing down the number of useable films by a considerable amount. The <em>TMDb</em> site describes itself as a 'trusted platform' (TMDb, n.d.) but as we have no means of inquiring how they obtain their data or how rigorously they check the accuracy of new information; we cannot declare this source as 100% reliable.</p>
                            
                            <p>We decided not to use the separate ratings file (ratings.csv) that collated <em>MovieLens</em> ratings for individual movies, and instead use the ratings given by <em>TMDb</em> users in the movies_metadata.csv file. This was because the amount of votes one each film was larger than the amount on <em>MovieLens</em> which we hoped would lead to more representative ratings for us to analyse. How reliable these ratings are is not only the very problem our project is trying to solve, but also somewhat impossible. We rely on users to have given an accurate rating for their opinion of the film, but have no way of verifying this. As <em>TMDb</em> is a community site as opposed to <em>Rotten Tomatoes</em> where official critics can give reviews, it may be suggested that <em>TMDb's</em> ratings are not as 'esteemed' as other sources. However, given that this project aims to evaluate ratings as a whole (not only reviews given by professionals) this seems appropriate for our research.</p>
                                
                                 <section id="cleaning" class="main"><br><br></section>
                                
                                <h3><b><u>What we did</h3></u></b>
    
    <h4><b><em>Cleaning</em></b></h4>
        
        <p>To view the code we used to clean the data, click here <a href="
        fivegoldstars.github.io/python_code/Extraction and Cleaning Final.ipynb
            ">here.</a></p>
    
    <p>The first step in cleaning the data was removing unnecessary columns like runtime or production country in order to create a dataframe more focussed for our needs. Then, we removed from our dataframe every movie with missing quantitative information because for sufficient analysis we needed complete information for all variables in order to gain a complete view of the data. In addition we filtered out films that have yet to be released. 
</p>
    
    <p>This process reduced the number of usable films from 45000 to 5023. </p>
    
<h4><b><em>Merging</em></b></h4>
    
    <p>Next, we merged the three separate .csv files (movies_metadata, credits and ratings) into one dataframe. We did this by merging on the movie id (a unique number assigned to each movie). </p>
    
    <h4><b><em>Improving Readability</em></b></h4>
    
    <p>In this step we removed unnecessary formatting in the columns to make them more readable, both for the programme and the humans working with it. For example, the cast column contained information on the name of the characters and links referring to the actor’s IMDb page. As we were only interested in the gender of the cast we removed the excess data as well as removing the stylistic parentheses and inverted quotes.  We then ended up with the genders of cast members represented as numbers with 2 representing male, 1 representing female and 0 representing unknown (information not logged on TMDb).  
</p>
    
    <h4><b><em>Calculating Male/Female Ratio</em></b></h4>
    
    <p>As percentage male/female cast was a variable we wanted to analyse, we needed to calculate this information as it wasn’t present in the dataframe. To do this, we first added new columns for the number of males, females and unknown and the size of the cast. We then created a for loop going through each row and counting how often a 2, 1 or 0 appears and stored this information in the newly created columns. The size of the cast was the length of the array in the cast column.  

We then decided to remove movies that had ‘unknown’ cast members. This was because if a movie had for example 2 male and 3 female actors, but 6 unknown there is not sufficient information to accurately estimate the gender split. For the remaining movies we added columns with the percentages of male and female actors by dividing the number of males/females in a film by the overall cast size. 
</p>
    
    <h4><b><em>Weighted Rating</em></b></h4>
    
    <p>We decided to calculate a weighted rating for each movie because of the big differences in vote count for some movies. ‘Weighted’ refers to the fact that some votes are given a greater weight, for example if two movies have a rating of 5.4 but one movie has 14 votes and the other 340, the rating of the first movie would have less significance on the overall average.  
</p>
    
    
    <h4><b><em>Problems</em></b></h4>
    
    <p>The biggest obstacle we faced was during the first part of cleaning the data.
During the merging phase, we found that Python wasn’t reading the datatypes of each column correctly and was instead reading columns containing numbers (such as movie ID) as strings, which made the data practically unusable when trying to write appropriate code. To combat this, we had to re-establish the datatype of the ID column as integers. Moreover, after successfully merging the data frames, we noticed that the overall number of movies actually went up. After investigating through various parts of the data frame, we noticed that the merging produced some duplicates, which needed to be deleted.
</p>
                                
                                 <section id="ethics" class="main"><br><br></section>
                                
                               <h3> <b><u>Ethics</h3></u></b>
    
    <p>Even though the datasets we used are publicly available to everyone, it is important to consider ethical implications especially in regard to the source of the data. The dataset was published on <a href="http://kaggle.com"> <em>Kaggle</em></a>, with this particular dataset being a mixture of data collected from <a href="http://themoviedb.org"><em>TMDb</em></a><a href="http://themoviedb.org"> and <a href="http://grouplens.org"><em>GroupLens<a href="http://grouplens.org"></em></a>. In terms of numbers for budget and revenue the data comes from the TMDB Open API (<em>TMDb</em> is a community led website). A look into their user guidelines reveals that they recommend the websites <a href="http://boxofficemojo.com"><em>BoxOfficeMojo</em></a> and <a href="http://the-numbers.com"><em>The Numbers</em></a> as sources for budget and revenue data.
</p>
    
        <p><em>The Numbers</em> is directed by <em>Nash Information Services, LLC</em> “the premier provider of movie industry data and research services.” Because of their close link with industry professionals we can assume this data has been acquired ethically and legally, and not through alternative means such as an invasion of privacy as seen with the Sony Pictures Hack in 2014. 
</p>
    
    <p>In terms of the ratings and vote count we decided to only use data from <em>TMDb</em> users and not from GroupLens research because the latter got the data from an API on the website <em>MovieLens</em> which is less popular than  <em>TMDb</em>. The  <em>TMDb</em> website is operated by <em>Fanhattan Inc</em>. In order to rate films, a user has to register with their email and create a username. In their Privacy Policy, <em>Fanhattan Inc.</em> states that they collect data from their users such as location, favourite movie genres or searches, which becomes associated with the personal information provided by the user. However before they share this data with third parties or use it for example by tracking usage patterns or performing analytics, they “create anonymous data records from [the user’s] personal information ("Anonymous Data") by excluding information (such as [the user’s] name) that makes the data personally identifiable to [the user].” All the data we used was therefore anonymized and didn’t allow for any conclusions on the identity of the users. The only names stated are of the actors and crew members of the films, which is publicly available data. 
</p>
								
							</section>
        
         <!-- Polar Chart-->
			
                
                <section id="polar" class="main">
                                <h2>Polar Chart</h2>
                    
                    <iframe width="100%" height="700" frameborder="0" scrolling="no" src="//plot.ly/~qm2group11/85.embed"></iframe>
                    
                    <h3><b><u>Why we made the chart </u></b></h3>
                    
                    <p>In order to display all our data in one visualisation and make initial, general comments we decided to create a polar chart. This visualisation is interactive, allowing us to clearly display all 5023 data points that readers can explore through looking at different sections of the chart. Whilst the limitations for this visualisation are that no statistical analysis can be performed on it so the results are not conclusive, it gives a good starting point for understanding the nature of our data, with more in-depth statistical analysis following in the next section. It also allowed a good display of all data points without appearing as cluttered as a Bubble Graph. 
</p>
                    
                    <p>The graph was created using plot.ly’s online chart studio and can be viewed in greater detail <a href="https://plot.ly/~qm2group11/85">here</a>. 
</p>
                    
                    <h3><b><u>How to interpret the chart</u></b></h3>
                    
                    <p>Four different variables are represented on the polar chart: average rating, box office revenue, genre and film budget. Theta represents the average rating (with each rating multiplied by 36 to scale to the 360 axes, e.g. a film with an average rating of 7 is represented with theta 252); radius represents box office revenue in dollars; the colour of the data point represents the genre of film as described by the legend on the left;  and the size of the data point corresponds to the size of the budget. 
</p>
                    
                    <p>Hovering over a datapoint gives you the title of the film, the radius, theta value, and genre. To filter the data according to revenue, place the cursor at the lower limit of revenue you want and drag outwards to the upper limit of revenue. For example, if you wanted to see all films with a revenue of above 2 billion dollars but below 2.5 billion dollars, you would click and drag from the 2 billion dollar radial outline outwards to the 2.5 billion dollar radiar line. To zoom out again click twice on the chart. To filter between different genres, double click on the name of the genre in the legend on the right hand side. 
</p>
                    
                    <h3><b><u>Initial thoughts</u></b></h3>
                    
                    <p>As previously mentioned, no particular statistical analysis can be performed on this graph but there are some clear initial findings: </p>
                    
                    <ul>
                    
                    <li> the most successful films (as these are the only ones that can be seen when the chart is at its default zoom setting, and data that has the largest radius revenue) have a rating between 5 and 9
</li>
                    <li>the highest grossing films appear to have ratings between 8 and 9 which suggests at least that the most successful films of our dataset have good ratings, but this correlation may not be true throughout the entire scope of our data
</li>
                    <li><em>Avatar</em> is the highest grossing film in our dataset, but does not have the highest rating nor the largest budget, suggesting that the three variables are not mutually dependent
</li>
                    <li>amongst the highest grossing films, the Action and Science Fiction genres at a glance appear to be the most present, however as this is visual analysis it is impossible to apprehensively draw any conclusions. This does however support Brewer & Josefowicz (2000)’s results suggesting there is a correlation between genre familiarity and box office success. 
</li>
                    
                    </ul>
                    
                    <h3><b><u>Thoughts from literature review</u></b></h3>
                    
                    <p>One benefit of the polar chart is it allows for direct analysis between films. Although this does not help establish overall trends, it does allow for shallow investigations to be conducted into the claims made in the ‘For and Against Ratings’ section of the report, as well as the validity of the research discussed in the Literature Review. 
</p>
                    
                    <p>Whilst neither <em>Crazy Rich Asians</em> or <em>Black Panther</em> appears in our cleaned data, <em>Joy Luck Club</em>, a 1993 film featuring a majority Asian-American cast, is similar in terms of being focussed on one ethnic group and promoting a specific cultural identity. Although it premiered in a different cultural climate, as shown in the image below in comparison to other drama films with a similar revenue, it had a better rating. This may be due to it being a culturally differentiated product, scoring higher ratings due to its perceived ‘difference’ in comparison to other films at the time. Whilst its box office revenue is not drastically high, it may be interesting in future to plot its success along similar films from 1993 with a majority white cast. </p>
                    
                 <div style="width:100%">
<div class="row">
  <div class="column" style="font-size:80%; text-align:center; align-content: center">
      <img src="http://fivegoldstars.github.io/images/data1.png" style="max-height:350px; max-width: 100%; "  align="middle"/><br>
  </div>
  <div class="column" style="font-size:80%; text-align:center">
    
    <img src="http://fivegoldstars.github.io/images/data2.png" style="max-height:350px; max-width: 100%; " align="middle"/><br></div>
</div>
    </div>
                    
                  
<p>There can be some observations made between differences in genre. For films with a revenue between 0 and $500 million, films in the drama category have a wider range of ratings, with a higher maximum rating in comparison to films in the action and adventure category. However, there is a higher concentration of adventure and action films in this range. This would make adventure and action 'familiar' genres, and so they should be more successful according to Brewer and Jozefowicz (2009), which is reflected in how more of these films seem to achieve higher revenue. </p>    
                    
                    
                 <div style="width:100%">
<div class="row">
  <div class="column3" style="font-size:80%; text-align:center; align-content: center">
      <img src="http://fivegoldstars.github.io/images/drama.png" style="max-height:350px; max-width: 100%; "  align="middle"/><br><em>Distribution of ratings within the Drama genre with revenues from 0 to $500 million</em>
  </div>
  <div class="column3" style="font-size:80%; text-align:center">
    <img src="http://fivegoldstars.github.io/images/adventure.png" style="max-height:350px; max-width: 100%; " align="middle"/><br><em>Distribution of ratings within the Adventure genre with revenues from 0 to $500 million</em></div>
  <div class="column3" style="font-size:80%; text-align:center">
    <img src="http://fivegoldstars.github.io/images/action.png" style="max-height:350px; max-width: 100%; " align="middle"/><br>
    <em>Distribution of ratings within the Adventure and Action genre with revenues from 0 to $500 million</em></div>
</div>
    </div>
                    
                    <p>This is furthered by how when zooming out on the graph to look at all the films, drama as a genre appears to consistently have less box office success in comparison to adventure, although this may be due to outliers such as <em>Avatar.</em> In which case, the correlation between genre and revenue isn't particularly strong. </p>
                    
                                     <div style="width:100%">
<div class="row">
  <div class="column3" style="font-size:80%; text-align:center; align-content: center">
      <img src="http://fivegoldstars.github.io/images/drama2.png" style="max-height:350px; max-width: 100%; "  align="middle"/><br><em>Distribution of ratings within the Drama genre with revenues from 0 to $2.5 billion</em>
  </div>
  <div class="column3" style="font-size:80%; text-align:center">
    <img src="http://fivegoldstars.github.io/images/adventure2.png" style="max-height:350px; max-width: 100%; " align="middle"/><br><em>Distribution of ratings within the Drama genre with revenues from 0 to $2.5 billion</em>
  <div class="column3" style="font-size:80%; text-align:center">
    <img src="http://fivegoldstars.github.io/images/action2.png" style="max-height:350px; max-width: 100%; " align="middle"/><br>
    <em>Distribution of ratings within the Drama genre with revenues from 0 to $2.5 billion</em>
</div>
    </div>
                    
                    <p>When trying to compare Marvel vs DC studios (as this information is not present in the cleaned dataset) at a glance, it does appear that Marvel films in general perform better at the box office. For instance, DC’s <em>Dark Knight</em> scores a higher rating than <em>Avengers: Age of Ultron</em>, but <em>Age of Ultron</em> had a higher revenue. Another interesting thing to note is that <em>Guardians of the Galaxy 2</em> had higher revenue than <em>Guardians of the Galaxy</em> but scored a lower average rating, perhaps linked to Brewer and Jozefowicz (2009)’s other conclusion that a successful film prequel leads to higher revenue for subsequent films. 
                        
</p>
                    
                    <div style="width:100%">
<div class="row">
  <div class="column" style="font-size:80%; text-align:center; align-content: center">
      <img src="http://fivegoldstars.github.io/images/data4.png" style="max-height:350px; max-width: 100%; "  align="middle"/><br>
  </div>
  <div class="column" style="font-size:80%; text-align:center">
    
    <img src="http://fivegoldstars.github.io/images/data3.png" style="max-height:350px; max-width: 100%; " align="middle"/><br>
</div>
    </div>
                    
                    <div style="width:100%">
<div class="row">
  <div class="column" style="font-size:80%; text-align:center; align-content: center">
      <img src="http://fivegoldstars.github.io/images/data5.png" style="max-height:350px; max-width: 100%; "  align="middle"/><br>
  </div>
  <div class="column" style="font-size:80%; text-align:center">
    
    <img src="http://fivegoldstars.github.io/images/data6.png" style="max-height:350px; max-width: 100%; " align="middle"/><br>
</div>
    </div>
                    
                    <p>All in all, the context of a film may contribute  to its success at the box office, which is something the polar chart can not demonstrate. Whilst the polar chart is useful for comparing films in a case by cas ebasis, the descriptive analysis in the following section helps establish a more general picture evidenced by statistics. That being said, there may be a story the data can't tell, such as whether or not <em>Joy Luck Club's</em> revenue was due to good narrative elements or due to its cultural identity. 
                        
                        <p>This can be further demonstrated by certain outliers in the data. For instance, <em>The Silence of the Lambs</em> performed particularly well but had a comparatively small budget, whilst although <em>Speed 2: Cruise Control</em> should have performed better than the first <em>Speed</em> film (according to Brewer and Jozefowicz (2009)), it performed worse. This could be related to the film having a different cast, as opposed to the effect of film ratings or film budget. </p>
                        
                        
                        <p>While the polar chart is a good way to display all our data at once and make shallow generalisations, we must still rely on statistical methods to calculate whether or not there is any correlation between the different variables.
</p>
							</section>


<!--Descriptive Analysis-->
        
        <section id="descr" class="main">
            
            <h2><b>Descriptive Analysis</b></h2>
            
            <div id="toc_container">
<ul class="toc_list">
  <li><a href="#overalldata"><b>1. Analysis on the overall datasets</b></a>
  <ul>
    <li><a href="#revdistribution">Distribution of Revenue</a></li>
    <li><a href="#ratingdistribution">Distribution of Rating</a></li>
  </ul>
</li>
 <li><a href="#relationships"><b>2. Analysis on relationships</b></a>
  <ul>
    <li><a href="#revratings">Revenue and Ratings </a></li>
    <li><a href="#revgender">Revenue and Gender</a></li>
      <li><a href="#revbudget">Revenue and Budget</a></li>
      <li><a href="concdesc">Conclusions</a></li>
  </ul>
</li>
</div>

<p>This section summarises our data systematically and uses it to evaluate the relationships between film ratings/ film gender-split/ film budget and film revenue. We then visualised these relationships using tables plotted in SPSS and graphs plotted in python before relating our findings back to our hypotheses.

    
    <p>To view the code used to create the following visualisations, please click <a href="
        fivegoldstars.github.io/python_code/data visualisations.ipynb
        ">here.</a></p>


</p>

                <section id="overalldata" class="main"><br><br></section>
                
                <p><b><u><h3>1. Analysis on the overall datasets</h3></u></b></p>

<p>We first looked at the distributions of film revenue and ratings as our main aim was to uncover whether a relationship existed between these two variables. To help us we used frequency tables, descriptive statistics and histograms were used for the analysis (SAS Institute Inc., 1999).</p>
            
            <p>Frequency tables show how often a particular value in a dataset appears. For example, you might have a list of grades for an exam; 7, 8, 9 (these would be the different values), which would appear on the left-hand side, and on the right the number of times this grade was achieved by a pupil (frequency). More advanced frequency tables then show what percentage of the overall results this frequency represents.
</p>
            
            <p>In our frequency tables the most left-hand column (in grey) represents the mean value-intervals for each variable e.g. if our dataset had revenue intervals of $5 billion, $6 billion, $7 billion etc. (these would be the value intervals), the mean value intervals would take the mean between $5 and $6 billion, $6 and $7 billion etc. and show those results. This way we can see within what specific range of e.g. revenues, most films lie.  For example, if 96% of films were shown to have a mean interval-value of $5.5 billion, we would know that 96% of films had a revenue of between $5 and $6 billion.
</p>

                <section id="revdistribution" class="main"><br><br></section>
                
                <p><b><h4><em>Distribution of Revenue:</h4></b></em></p>

<p>We constructed Figure 1, Figure 2 and Figure 3  to look at the distribution analysis of the film revenue.</p>
            
            <p>In Figure 1, the mean value intervals (on the left in grey), stand for the different ranges in film revenue. It shows that 4,302 films lie on the mean interval-value of 100 million, suggesting their revenues range from $0 to $200 million. Furthermore, as seen from the percentage values, 86.7% of films collected obtained a revenue of within this range.
</p>
            
            <p>According to the Revenue Statistics in Figure 2, the average revenue for the films is $146 million. The film with minimum revenue only obtained $1, which is indicated as 100 million on Figure 2. This is because SPSS only demonstrates interval range. Similarly, the one with maximum revenue obtained $2788 million, displayed as 2700 million.
</p>


<div style="width:100%">
<div class="row">
  <div class="column1" style="font-size:80%; text-align:center; align-content: center">
      <img src="http://fivegoldstars.github.io/images/newfreq.png" style="max-height:350px"  align="middle"/><br><em>Figure 1: Frequency table for revenue</em>
  </div>
  <div class="column2" style="font-size:80%; text-align:center">
    
    <img src="http://fivegoldstars.github.io/images/Screenshot%202019-01-14%20at%2011.01.51.png" style="max-height:350px;" align="middle"/><br><em>Figure 2: Descriptive statistics table for revenue</em></div>
</div>
</div>

<p><br>In addition, we plotted the frequency table graphically into a histogram, as shown in Figure 3.


</p>

<div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/hist2.png"  style="padding-bottom:0.5em; max-height:350px; " /><br><em>Figure 3: Histogram showing frequency for revenue</em></div>
                    <br>

<p><br>In addition, our histogram (Figure 3) visually represents the mean-interval values and indicates the skewness in the data (86.7% of films obtained revenues from $0-200 million). Histograms are often used to test how far and in which direction a skew is deviated from the horizontal symmetry of a normal distribution (Brownmath, 2016). The histogram above demonstrates a positive skewness of 5.34, which is defined as highly skewed (Brownmath, 2016). This means that the majority of the films in our dataset obtained a revenue at the lower, rather than higher end of the range.






</p>

                <section id="ratingdistribution" class="main"><br><br></section>
                
                <p><em><b><h4>Distribution of Rating:</em></h4></b></p>

<p>We constructed Figures 4, 5 and 6, for the distribution analysis of the film rating.

</p>

<p>Figure 4 shows the mean-interval values and corresponding frequencies for weighted ratings. This shows that 2,904 films had ratings between 5 and 6 and 1,825 films had ratings between 6 and 7. In turn, we can see that 95.3% of all films were between these two ranges of ratings i.e. 95.3% of films received a rating of between 5 and 7. Figure 5 shows that the average film rating was 6.08 (which is slightly higher than the median rating-value of 5 (in a range between 0 and 10)). Furthermore, as the minimum and maximum ratings were 4.8 and 8.25 respectively, this suggests that the range of ratings given tended to be above the median rating-value.
</p>
            
            <p>Figure 6 visualises the positive skewness of 0.884, which is defined as moderately skewed (Brownmath, 2016) due to a majority of films receiving ratings between 5 to 7. Nevertheless, it should be noted that this positive skew is within the range of ratings (4.8 to 8.25), not the total range of ratings available (0-10). This could therefore suggest that instead of the majority of films having a rating in the lower range, films are actually more likely to be rated above average (if we take the average as the median 5).
</p>
                    

<div style="width:100%">
<div class="row">
  <div class="column1" style="font-size:80%; text-align:center; align-content: center">
      <img src="http://fivegoldstars.github.io/images/frequencytableforweightedrating.png" style="max-height:350px; max-width: 100%; "  align="middle"/><br><em>Figure 4: Frequency table for weighted rating</em>
  </div>
  <div class="column2" style="font-size:80%; text-align:center">
    
    <img src="http://fivegoldstars.github.io/images/descriptivestats2.png" style="max-height:350px; max-width: 100%; " align="middle"/><br><em>Figure 5: Descriptive statics for weighted rating</em></div>
</div>
    </div>


</p>

<div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/histogram1.png"  style="padding-bottom:0.5em; max-height:350px;" /><br><em>Figure 6: Histogram showing frequency for weighted rating</em></div>




</p>
                
                <section id="relationships" class = "main"><br><br></section>

<p><b><u><h3>2. Analysis on relationships</b></h3></u></p>

<p>This section will test our central hypothesis by determining the relationship between film ratings and their corresponding film revenue.


</p>

<p>For the analysis of revenue and ratings, we used cross tabulation to determine the relationship between the two variables in depth. Cross tabulation is a table that summarises the frequency of variables according to defined features i.e. it gives us a more in depth view into the range of ratings within films with higher revenues and lower revenues.  

    <p> 
Film revenue was our dependent variable across all visualisations (y-axis). Furthermore, for the graphs where the independent variable is categorical, including bar charts and violin graphs, the film revenue was converted to average revenue for each interval.
</p>

</p>

                <section id= "revratings" class="main"><br><br></section>
                
                <p><em><b><h4>Revenue and Ratings</h4></b></em></p>

  
<p>Our visualisations indicate that there is a weak relationship between film ratings and film revenue. This is seen in figure 7 where the line of best fit on the scatterplot is not very steep.
<p>Some films with higher ratings (7 or above) did the highest revenues (above $1.5 billion). However, this was only 3 films meaning the initial correlation may not be statistically significant. Contrastingly, the majority of films are concentrated around the line of best fit and below the $1billion revenue mark. Furthermore, high ratings did not always correspond to high revenue. A large proportion of films rated above 7.5 made less than $0.5 billion.
</p>
                                         
                            
                                         
<div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/ratingrevenue.png"  style="padding-bottom:0.5em; max-height:350px;" /><br><em>Figure 7: Scatter graph showing correlation between film revenue and film ratings</em></div>

                                           <p>Figure 8 and 9 shows the distribution of film revenues by ratings in the form of a bar chart. These suggest that the highest rated films (ratings of 7 and 8) made the most money, with those with a more ‘middle’ rating (between 5 and 7) making the least. Furthermore, it appears that the lowest rated films actually had a higher revenue than the ‘middle’ rated films. This suggests again that there is a potentially weak positive correlation between ratings and revenues which is more noticeable than in the scatter graph. Nevertheless, as mentioned before, it should be noted that most films were still rated above the median available rating (5), suggesting that either the majority of films are ‘above average’ or that people have a tendency to rate films more positively.
</p>
            
<div style="width:100%">
<div class="row">
  <div class="column" style="font-size:80%; text-align:center; vertical-align: middle">
      <img src="http://fivegoldstars.github.io/images/ratingbarchart1.png" style="max-height:350px; vertical-align: middle; max-width: 100%" /><br><em>Figure 8: Bar chart showing the distribution of ratings and revenue</em>
  </div>
  <div class="column" style="font-size:80%; text-align:center; vertical-align: middle">
    
    <img src="http://fivegoldstars.github.io/images/ratingbarchart2.png" style="height:350px; vertical-align: middle; max-width: 100%" /><br><em>Figure 9: Bar chart comparing revenue and films with a rating of 5 to 8</em></div>
</div>
</div>
                                         
                                         <p>Similarly Figure 10 (violin chart) visually reveals the distribution of revenue within each film rating. According to the graph, most films have revenue below $0.5 billions and the highest revenue appeared in films rated 7.
 
</p>

<div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/ratingviolin.png"  height="450px" style="padding-bottom:0.5em; max-width: 100%" /><br><em>Figure 10: Violin chart showing the distribution of revenue within each film rating </em></div>
                                         
                                         <p>We then used cross tabulation to reveal the exact percentages of films lying within certain distributions.  Figure 11 suggests that all low-rated films have relatively low revenues. 94.1% of films rated between 5 and 6 obtained revenues between the lowest interval range $0-$200 million (mean interval-value of $100 million). Similarly, 80.5% of films rated between 6 and 7 were also in this lowest revenue interval range. In contrast, higher rated films were more distributed in how much money they made. 42.4% of films rated 7 to 8 made between $0-200 million. However, another 20.5% made between $200 - $400 million ($300 million mean interval-value) and 13.4% made between $400 - $600 million ($500 million mean interval-value). For films rated between 8 and 9 20% made between $1,000-$1,200 million. Furthermore, none of the films with low ratings obtained high revenues.
</p>
                                         
                                         <p>This implies that our first hypothesis might be rejected as the majority of low-rated films obtained relatively low revenues and only the highest rated films obtained the high revenues. Film revenue therefore, does appear to initially correspond with film ratings.
</p>

                                         
                                         <p>Nevertheless, it should be taken into account that only a very small number of films obtained high revenues and the majority of films fell within the lowest range and made between $0-$200 million.
</p>
                                         
                                         <div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/weightedratingtab.png"  style="padding-bottom:0.5em; max-height:500px;" /><br><em>Figure 11: Revenue * Weighted Rating Crosstabulation</em></div>

                                         
                <section id="revgender" class="main"><br><br></section>
                
                <p><em><b><h4>Revenue and Gender</h4></b></em></p>

<p>The scatterplots (Figures 12 and 13) show that the relationships between % of actors in films which are male and % of actors in films which are female, are symmetrical. This is because for each film the percentage of male and female adds up to be 1, resulting in complementary distributions. For instance, films where 20% of actors were males have 80% of actors who are female.
</p>

<p>These scatterplots show the trend that films with a moderately high proportion of male actors make more money. More specifically, Figure 12 shows that films increased in revenue as their % of actors who were male augmented from 0 to 80%. Films which had 80% male actors obtained the highest average revenue. The result for the % of female actors is therefore the opposite of this (Figure 13). Nevertheless, it should be noted that this relationship appears to be incredibly weak and the majority of films obtained a similar revenue despite the % of male or female actors. A statistical analysis (carried out in the next section), will determine whether there is any significance to the relationship.
</p>
            
<div style="width:100%">
<div class="row">
  <div class="column" style="font-size:80%; text-align:center; vertical-align: middle">
      <img src="http://fivegoldstars.github.io/images/malereg.png" style="height:350px; vertical-align: middle; max-width: 100%" /><br><em>Figure 12: Scatter plot showing the relation between revenue and percentage of male actors</em>
  </div>
  <div class="column" style="font-size:80%; text-align:center; vertical-align: middle">
    
    <img src="http://fivegoldstars.github.io/images/femalereg.png" style="height:350px; max-width: 100%; vertical-align: middle" /><br><em>Figure 13: Scatter plot showing the relation between revenue and percentage of female actors </em></div>
</div>
</div>
                                         
                         <section id="revbudget" class="main"><br><br></section>
                
                <p><em><b><h4>Revenue and Budget</h4></b></em></p>
                                         
<p>On the other hand, there appears to be a strong positive correlation between revenue and budget. This is illustrated by the steep best-fit line that is closer to the y=x function than to the horizontal axis. Although many films lie on the lower end of the scale (i.e. budget below $150 million, revenue below $0.5 billion), the majority of points do appear to hug the line of best fit closely. Of course, it must be noted that there are outliers. However, these are only a handful in comparison to the 5,000 or so films represented on the plot. Furthermore, films with an incredibly high budget (between $220million-$400million) actually made less money. This could be because they have to make more in the box office comparatively, in order to break even and make a profit in the first place. These results therefore suggest that budget may be the best predictor of film box-office success. Further statistical analysis will be carried out in the next section to uncover if this is true.  
</p>
                                         
                                         <div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/budgetreg.png"  height="350px" style="padding-bottom:0.5em;" /><br><em>Figure 15: Scatter plot showing the correlation between film budget and film revenue </em></div>
                                         
                                       <section id="concdesc" class="main"><br><br></section>
                                         
                                         
                <p><em><b><h4>Conclusion</h4></b></em></p>
<p>Our descriptive analysis can be concluded into four parts. Firstly, to summarise the distribution of the overall data, most films lie in the category of low revenue and low ratings compared with the overall range of revenues. Secondly, our data has demonstrated that low rated films received lower revenue, high rated films were more likely have high revenues and the majority of films were rated moderately highly in comparison to the range of ratings available (0-10).  However, it does not conclusively show that high rated films receive higher revenue. Thirdly, films with a higher percentage of male actors tended to have higher revenues than those with high percentage of female actors. However, having a very high percentage of male actors actually generated a low revenue. Last but not least, there is a positive correlation between film revenue and budget, although this is subject to the extreme case where very high budget actually corresponds to a lower revenue. This may be because a higher amount of revenue is needed for the film to turn a profit.
</p>
            
</section>
                

                              
                
                 <!--Statistical Analysis-->
                
<section id="statsan" class="main">
<h2><b>Correlation Analysis</b></h2>

    
<div id="toc_container">
<ul class="toc_list">
    <li><a href="#statsintro">Introduction</a></li>
    <li><a href="#revsratings">Revenue vs Ratings</a></li>
     <li><a href="#revsbudget">Revenue vs Budget</a></li>
     <li><a href="#revsmale">Revenue vs Gender (Male Actors)</a></li>
    <li><a href="#revsfemale">Revenue vs Gender (Female Actors)
    </a></li>
    <li><a href="#statsconclusion">Conclusion
    </a></li>
 
</div>
    
                
    <section id="stastintro" class="main"><br><br></section>
    
    <h3><b><u>Introduction</u></b></h3>
    
<p>Correlation analysis depends to some extent on making assumptions about the collected data and choosing the most suitable way of comparing that data. The performance of the correlation analysis methods depends on the form of the analysed data and how it relates to the approach being used. There are parametric and nonparametric test methods. Parametric ones, such as Linear Regression and Pearson Correlation Coefficient, assume that sample data comes from a population that follows a probability distribution based on a fixed set of parameters. In contrast, a nonparametric test, such as Kendall’s Tau and Spearman’s Rank Correlation Coefficient, is suitable for data for which the parameter set is not fixed. Nonparametric tests work for data which does not follow any distribution or has a specified distribution but with unspecified parameters (Freedman,  2005).

</p>
    
<p>Relying on a fixed parameter set, parametric models assume more about a given population than nonparametric methods do. When the assumptions are correct, parametric methods produce more accurate estimates compared to nonparametric methods. However, as more is assumed by a parametric test, when the assumptions are not correct, there is a bigger risk of them failing (Statistics Solutions, 2019).


</p>

<p>In this project, the sample data collected on revenues, rankings, gender and budget is data with no specified distribution. Therefore, only nonparametric tests could be used to determine the correlation between revenue and 3 different variables (rankings, gender and budget). The two accepted tests of nonparametric rank correlations are Kendall’s tau and Spearman’s Rank Correlation Coefficient (Spearman’s rho). These two tests assess statistical associations based on the ranks of the data to measure the strength of the relationship between two variables. In most of the situations, the interpretations of Kendall’s tau and Spearman’s rho are very similar and, thus, lead to the same conclusions (Statistics Solutions, 2018).

</p>
    
    <p>Nevertheless, there are a few minor differences between the two tests which make them suitable for various datasets. Compared to Spearman’s rho, Kendall’s tau produces usually smaller values, it is insensitive to error and its p-values are more accurate with smaller sample sizes. While Kendall’s tau’s calculations are based on concordant and discordant pairs, Spearman’s rho’s calculations are based on deviations. Finally, correlation coefficient values are between 1 and -1 for both tests (Statistics Solutions, 2018).


</p>
    
    <p>Since samples of revenues, rankings, gender and budget vary in size and distribution (and possibly in some other ways), both Spearman’s rho and Kendall’s tau tests were conducted to pick up differences in accuracies between the two and strengthen reliability of conclusions made after verifying results.
</p>
    
    
    <p>To conduct Spearman’s rho, the following conditions must be satisfied:<ul>
<li>the two variables should be measured on an ordinal, interval or ratio scale,</li>
<li>there is a monotonic relationship between the two variables.</li>
</ul>
    
    <p>To conduct Kendall’s tau, the following conditions must be satisfied:
<ul>
<li>the two variables should be measured on an ordinal or continuous scale,
</li>
<li>there is a monotonic relationship between the two variables.
</li>
</ul>
    
    <p>Explained at statistics.laerd.com (statistics.laerd.com, 2019), the conditions of Spearman’s rho and Kendall’s tau tests are satisfied by the datasets collected in this project (revenue, ratings, gender, budget).


        
        <p>To determine whether the correlation between revenue and 3 variables (ratings, budget and gender) is significant, the p-value was compared to the significance level of 0.05. Significance level of 0.05 indicates that there is a 5% chance to conclude that a correlation exists even when it actually does not. The p-value also indicates whether the correlation coefficient of the relationship between two variables is significantly different from 0 (statistics.laerd.com, 2019).

</p>
    
    <p>When the p-value ≤ 0.05, the correlation is said to be “statistically significant” and it can be concluded that the correlation is different from 0.

</p>
    
    <p>When p-value > 0.05, the correlation is said to be “not statistically significant” and it cannot be concluded that the correlation is different from 0.


</p>
    
    
<p>To view a step by step process of how the analysis was executed using Python, click <a href="https://github.com/fivegoldstars/fivegoldstars.github.io/blob/master/python_code/Statistical%20Analysis.ipynb">here.</a></p>
    
    
    <section id="revsratings" class="main"><br><br></section>
    
    <h3><b><u>Revenue vs Ratings</u></b></h3>
    
    <div style=" font-size:80%; text-align:center; max-width: 100%"><img src="http://fivegoldstars.github.io/images/code1.png"  height: 250px  style="padding-bottom:0.5em; max-width: 100%; max-height: 250px"  /></div>
    
    <p>Spearman’s rho correlation coefficient (rs) = 0.296, p-value = 5.87x10-<sup>102</sup>
        <p>Kendall’s tau correlation coefficient (τb) = 0.211 , p-value = 8.31x10-<sup>100</sup>
</p>
    
    <p><em>Spearman’s rho:</em> there was a weak, positive correlation between revenue and ratings, which was statistically significant (p-value ≤ 0.05). Thus, it can be concluded that the correlation is different from 0.
</p>
    
 <p><em>Kendall’s tau:</em> there was a weak, positive correlation between revenue and ratings, which was statistically significant (p-value ≤ 0.05). Thus, it can be concluded that the correlation is different from 0.
       </p>
    
    <section id="revsbudget" class="main"><br><br></section> <h3><b><u>Revenue vs Budget</u></b></h3>
    
    <div style=" font-size:80%; text-align:center; max-width: 100%"><img src="http://fivegoldstars.github.io/images/code2.png"  height: 250px  style="padding-bottom:0.5em; max-width: 100%; max-height: 250px"  /></div>
    
    <p>Spearman’s rho correlation coefficient (rs) = 0.707, p-value = 0.0
        <p>Kendall’s tau correlation coefficient (τb) = 0.523, p-value = 0.0
    
    <p><em>Spearman’s rho:</em>  there was a strong, positive correlation between revenue and budget, which was statistically significant (p-value ≤ 0.05). Thus, it can be concluded that the correlation is different from 0.

</p>
    
 <p><em>Kendall’s tau:</em> there was a fairly strong, positive correlation between revenue and budget, which was statistically significant (p-value ≤ 0.05). Thus, it can be concluded that the correlation is different from 0.
       </p>

    <section id="revsmale" class="main"><br><br></section>
    
    <h3><b><u>Revenue vs Gender (Male Actors)</u></b></h3>
    
    <div style=" font-size:80%; text-align:center; max-width: 100%"><img src="http://fivegoldstars.github.io/images/code3.png"  height: 250px  style="padding-bottom:0.5em; max-width: 100%; max-height: 250px"  /></div>

    <p>Spearman’s rho correlation coefficient (rs) = 0.0215, p-value = 0.591
	<p>Kendall’s tau correlation coefficient (τb) = 0.0152, p-value = 0.597
</p>
    <p><em>Spearman’s rho:</em>  there was a very small, positive correlation between revenue and gender (male actors), which was not statistically significant (p-value > 0.05). Thus, it cannot be concluded that the correlation is different from 0.


</p>
    
 <p><em>Kendall’s tau:</em> there was a very small, positive correlation between revenue and gender (male actors), which was not statistically significant (p-value > 0.05). Thus, it cannot be concluded that the correlation is different from 0.

           </p>
    
    <section id="revsfemale" class="main"><br><br></section>
    
    <h3><b><u>Revenue vs Gender (Female Actors)</u></b></h3>
    
    <div style=" font-size:80%; text-align:center; max-width: 100%"><img src="http://fivegoldstars.github.io/images/code4.png"  height: 250px  style="padding-bottom:0.5em; max-width: 100%; max-height: 250px"  /></div>

    <p>Spearman’s rho correlation coefficient (rs) = - 0.0319, p-value = 0.425

	<p>Kendall’s tau correlation coefficient (τb) = - 0.0222, p-value = 0.441

</p>
    <p><em>Spearman’s rho:</em>  there was a very small, negative correlation between revenue and gender (female actors), which was not statistically significant (p-value > 0.05). Thus, it cannot be concluded that the correlation is different from 0.



</p>
    
 <p><em>Kendall’s tau:</em> there was a very small, negative correlation between revenue and gender (female actors), which was not statistically significant (p-value > 0.05). Thus, it cannot be concluded that the correlation is different from 0.

       </p>
    
         
    <section id="statsconclusion" class="main"><br><br></section> <h4><b><em>Conclusions</em></b></h4>
    
<p>Ratings appeared to be a weak predictor of box office success. Similarly, there was no correlation between gender of cast and revenue. The best indicator of the level of revenue collected by a movie appear to be its budget. The larger the amount of money invested in a film, the more revenue it makes at the box office.



              </p>
                
</section>

                    <!--Results-->
								
                
    <section id="results" class="main"><br><br>
    
								<h2><b>Results and Discussion</b></h2>
                                    <h3><b><u>Results</u></b></h3>
        
        
        <p>Our central hypothesis was that film ratings will not predict box
office revenue. This was supported by both our descriptive and statistical
analyses. These demonstrated that while the films which made the most money
were relatively more highly rated than the majority of the films, this only
applied to a handful of films. Furthermore, the majority of films made
comparatively little money regardless of their rating. This was further backed
up by our statistical analysis which found a positive but very weak correlation
between film revenue and film rating (Spearman’s rho = 0.296, Kendall’s tau =
0.211). Therefore, while positive, the relationship is too weak to be
significant and films should not predict how much money they will make based
off of how highly they are rated.


 
</p>
        
        <p>Our second hypothesis stated that the gender of actors in films would predict box office success. While our descriptive analysis suggested there might be a weak relationship between these two factors our statistical analysis rejected this (Spearman’s rho = 0.0215, Kendall’s tau = 0.0152). This means we should reject our hypothesis as the percentage of male or female actors in films does not determine how much money the film will make in the box office.
</p>
        
        <p>Finally, our third hypothesis suggested that film budget would be
an indicator of box office success. This hypothesis was backed-up by both
descriptive and statistical analyses. Eliminating films which had the highest
budget (which corresponded to lower revenue), our visualisation showed a strong
positive correlation between film revenue and film budget. This was supported
by the Spearman’s rank and Kendall’s tau values (0.707 and 0.523 respectively).
Therefore, of the three variables we measured, it can be concluded that a film’s
budget is the best predictor of how much money that film will make in the box
office.


        
</p>
        
        
                                <h3><b><u>What Does the Data Tell Us?</u></b></h3>
        
        <p>Our central hypothesis was that film ratings will not predict box office revenue. Our descriptive analysis has demonstrated the following trends. First, most films are rated relatively low and received relatively low revenue. There are higher number of moderately rated films received higher revenue than the low rated ones.  Yet, this does not show the trend that highly rated films receive the highest revenue. This implies film ratings do not consistently correlate with box office revenue, which supports our central hypothesis. Moreover, this correlation can be further evidenced by our statistical analysis with a weak and positive correlation being found (a rather small Spearman’s rho of 0. 296 and Kendall’s tau of 0.211).</p>
        
        <p>Our statistical analysis found a very weak relationship between ratings and revenue, meaning that film ratings are a poor indicator of box-office success. While films with higher ratings did tend to earn more money, the converse was not true. Most films had relatively average ratings to high ratings. However, what is particularly interesting is that this distribution (seen in our bar charts) followed a similar distribution to Hu, Pavlou and Zhang’s j-shaped distribution of product reviews (2009). Their investigation suggests people are more likely to leave a review if their opinions are at either extreme (i.e. those giving 1- and 5-star ratings), as opposed to those in the middle (i.e. 3- and 4- stars), leading to a J-shaped distribution. This further supports our hypothesis that ratings are not reliable predictors of film-financial success as the review-system has a skewed bias. This could explain why findings are so varied and echoes our literature review pointing to consumers leaving reviews and ratings at the extremes (they are more likely to rate highly), skewing the data (Austin, 1983). Instead it is important to account for rating-prejudice and investigate other factors which may be influencing viewers intentions to watch films. Moreover, if not a forecast for success, our research calls into question the purpose of ratings in the first place. As the industry competes with the likes of subscription film services like Netflix, this investigation encourages film producers to uncover what truly drives viewers to the cinema.</p>
        
        <div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/budgetreg.png"  height="350px" style="padding-bottom:0.5em;" /><br><em>Distribution of Amazon Product Reviews (Hu et. al, 2009)</em></div>

        <div style="width:image width px; font-size:80%; text-align:center;"><img src="http://fivegoldstars.github.io/images/budgetreg.png"  height="350px" style="padding-bottom:0.5em;" /><br><em>Figure 16: Distribution of film ratings and film revenue</em></div>

        
        
        
        <p><br>The relationship between the gender of actors/ film budget and ratings as predictors of revenue success found contrasting results. Although men appeared to bring a higher revenue than women, there was no statistically significant relationship between having male or female actors in films and how much money films made. This result was inconclusive, meaning there may be another factor interacting with actors’ genders which affects film-revenue e.g. how famous an actor is. Other studies have pointed at the impact of celebrities on film-success (Treme & Craig, 2013) which could explain why famous models or singers are often cast. In contrast, there was a very strong relationship between a film’s budget and its revenue, suggesting the importance of having money to begin with. As noted in our literature review, this may be due to the ability of high budgets to influence the box-office of film’s with majority negative reviews (Basuroy et al., 2003). However, films with a very high budget did not make as much money, recommending that budget is not the only indicator of success. Nevertheless, out of the variables we measured budget acted as the strongest predictor, supporting previous findings that it has a statistically significant effect on revenue.

 </p>
        
        <p>Overall, interesting conclusions can be drawn from this project to influence film-producers’ strategies and question the role of ratings in general. Firstly, as actors’ genders have no/ questionable influence on film success there should be a more active role to address the gender imbalance in films (Women and Hollywood, 2018) given it will not impact film profit. Secondly, as budget does contribute to film-revenue, the industry should be aware of the struggles small film-production companies/ independent films face in succeeding,  due to lack of financing, and fund smaller teams to encourage diversity and avoid a monopoly by larger production companies. Finally, the value of ratings should be viewed critically across both film and other industries. Looking at e.g. the social value of ratings (Cheung et al., 2003) might be more useful. That is, ratings act as a social influencer by swaying recommendations e.g. a friend might recommend a film because of how terrible it is. Mining ratings by matching customer interests (e.g. suggesting films to consumers based off of what films they rate highly) may therefore be a more effective way of influencing purchasing decision than assuming that all higher rated films, or other products and services, automatically translate into more purchases and greater profit. Further research would therefore benefit from looking into the social value of ratings instead and their skewed nature. This could help identify the best use of ratings data for companies, who could potentially personalise their services/ products depending on what a consumer valued the most.</p>
                                    
                </section>
                
                 <section id="limits" class="main">
                     <h2><b>Limitations</b></h2>
                     
                     <p>Before accepting our findings, we should acknowledge certain limitations to our research.</p>
                     
                     <ol>
                         <li>We did not consider the difference that inflation has on our data concerning budget and revenue. Although initially we wanted to only look at films between 2015-2018 to limit the effects of inflation, when cleaning the data we realised this would not leave us with enough films to carry out statistical analysis.</li>
                         <li>Age restrictions on films limits their audience. This in turn may have impacted a film’s box-office success as films which can be viewed by a limited audience might sell less tickets. Nevertheless, films open to all will be those rated U and PG which tend to be children’s films. These might attract a limited audience because of the genre and therefore limit film-revenue although not to a great extent.

 </li>
                         <li>The distribution of our data meant we had to use non-parametric tests which are less accurate than parametric tests. However, as our data did not meet the prerequisites of parametric tests, it was inevitable that we would not be able to do this type of statistical analysis.</li>
                         <li>We cannot assume that actors’ genders and film-budget are the only factors affecting film-revenue success. For instance, a film’s marketing could affect how many viewers it gets; release date could increase/decrease competition i.e. if many films are released at the same time, they might struggle more to get viewers; foreign films might struggle against American/English films because of language barriers and actor popularity might entice audiences regardless of the quality of the film.

 </li>
                         <li>Unpredictability of consumer behaviour may be a limiting factor in comparing ratings and film financial success e.g. viewers may choose to see a film because of how bad it is.

</li>
                         <li>Data for 62 films went missing during our statistical and visual analysis which might have affected our results.

</li>
                         <li>What is considered as a high or low rating was defined by our judgement which may be subjective in comparison to the general population.</li>
                         <li>Finally, although we encountered a strong relationship between film budget and film revenue, we cannot assume that correlation is equal to causation. Nevertheless, budget should still be a matter of concern to the film industry in providing funding and access for smaller film productions to take place.

 

 </li>
                     
                     </ol>
                     
                     <p>Despite these limitations, there are still valuable conclusions to draw from our project. Namely, a call to re-evaluate the role ratings play in consumer purchase intention and how this can be harnessed. Furthermore, the data analyses carried out serve to mitigate limitations. Larger-scale research into the effect of ratings in other industries e.g. travel, would serve to uncover their value and what influence they truly exert.</p>
                </section>
                
                 <section id="ref" class="main">
                     <h2><b>References</b></h2>
                     
                     <h3><b><u>Why This Project? </u></b></h3>
                     
                     <ul>
                         
                         <li>Brueggemann, T. (2017). Marvel vs. DC at the Box Office: One Comes out on Top — but Not by Much. [online] IndieWire. Available at: https://www.indiewire.com/2017/11/marvel-vs-dc-box-office-rivalry-thor-ragnarok-justice-league-1201897782/ [Accessed 21 Jan. 2019].
</li>
                         
                         <li>Buckley, C. (2018). From Black Panther to Crazy Rich Asians: How 2018 finally proved to studios that actors of colour have global appeal. [online] The Independent. Available at: https://www.independent.co.uk/arts-entertainment/films/features/black-panther-crazy-rich-asians-blackkklansmen-2018-film-actors-of-colour-global-appeal-a8700591.html [Accessed 21 Jan. 2019]. 
</li>
                     <li> 
Connick, T. (2018). Black Mirror's 'Nosedive' episode is about to become reality in China - NME. [online] NME. Available at: https://www.nme.com/news/tv/black-mirrors-nosedive-episode-become-reality-china-2263309 [Accessed 21 Jan. 2019].
</li>
                         
                         <li>Gray, T.  (2019). Jon M. Chu on ‘Crazy Rich Asians’: ‘We Had a Sense of Purpose’. [online] Variety. Available at: https://variety.com/2019/film/news/jon-chu-crazy-rich-asians-1203105999/ [Accessed 21 Jan. 2019].
</li>
                     <li>Hall, C. and Boyle, B. (2019). Google Lens: What is it and how does it work? - Pocket-lint. [online] Pocket-lint. 
Available at: https://www.pocket-lint.com/apps/news/google/141075-what-is-google-lens-and-how-does-it-work-and-which-devices-have-it 
[Accessed 21 Jan. 2019]. 
</li>
                     
                     <li>McCarthy, K. (2016). Yelp-for-people app Peeple is back – so we rated Julia, its cofounder. [online] Theregister.co.uk. Available at: https://www.theregister.co.uk/2016/03/08/peeple_app_back_from_grave/ [Accessed 21 Jan. 2019].
</li></ul>
                     
                     
                     
                     <h3><b><u>Literature Review </u></b></h3>
                     
                     <ul>
                     
                     <li>Austin, B. (1983). Critics’ and Consumers’ Evaluations of Motion Pictures. Journal of Popular Film and Television, 10(4), pp.156-167.</li>
                         
                    <li>Basuroy, S., Chatterjee, S. and Ravid, S. (2003). How Critical are Critical Reviews? The Box Office Effects of Film Critics, Star Power, and Budgets. Journal of Marketing, 67(4), pp.103-117.</li>
                     
                    <li>Berg, J. and Raddick, M. (2016). First You Get the Money, Then You Get the Reviews, Then You Get the Internet Comments: A Quantitative Examination of the Relationship Between Critics, Viewers, and Box Office Success. Quarterly Review of Film and Video, 34(2), pp.101-129.</li>
                         
                     <li>Brewer, S., Kelley, J. and Jozefowicz, J. (2009). A blueprint for success in the US film industry. Applied Economics, 41(5), pp.589-606.</li>
                         
                         <li>Collins, A., Hand, C. and Snell, M. (2002). What makes a blockbuster? Economic analysis of film success in the United Kingdom. Managerial and Decision Economics, 23(6), pp.343-354.</li>
                         
                    <li>Desai, K. and Basuroy, S. (2005). Interactive influence of genre familiarity, star power, and critics' reviews in the cultural goods industry: The case of motion pictures. Psychology and Marketing, 22(3), pp.203-223.</li>
                         
                         <li>Eliashberg, J. and Shugan, S. (1997). Film Critics: Influencers or Predictors?. Journal of Marketing, 61(2), p.68.</li>
                         
                         <li>Gaenssle, S.,  Budzinski, O. and Astakhova, D. (2018).  Conquering the Box Office: Factors Influencing Success of International Movies in Russia. Ilmenau Economics Discussion Papers, 24 (113). Available at SSRN: https://ssrn.com/abstract=3193629</li>
                         
                         <li>Google. (2013). Quantifying Movie Magic with Google Search. Available at: https://ssl.gstatic.com/think/docs/quantifying-movie-magic_research-studies.pdf 
</li>
                         
                         <li>Help.imdb.com. (n.d.). IMDb | Help. [online] Available at: https://help.imdb.com/article/imdb/track-movies-tv/faq-for-imdb-ratings/G67Y87TFYYP6TWAV# [Accessed 22 Jan. 2019].
</li>
                         
                         <li>King, T. (2007). Does film criticism affect box office earnings? Evidence from movies released in the U.S. in 2003. Journal of Cultural Economics, 31(3), pp.171-186.</li>
                         
                         <li>Kusumasondjaja, S., Shanka, T. and Marchegiani, C. (2012). Credibility of online reviews and initial trust. Journal of Vacation Marketing, 18(3), pp.185-195.</li>
                         
                         <li>Maslowska, E., Malthouse, E. and Bernritter, S. (2016). The Effect of Online Customer Reviews’ Characteristics on Sales. Advances in Advertising Research. 7.  pp.87-100.</li>
                         
                         <li>Ravid, S. (1999). Information, Blockbusters, and Stars: A Study of the Film Industry. The Journal of Business, 72(4), pp.463-492.</li>
                         
                         <li>Smith, S. and Smith, V. (1986). Successful movies: A preliminary empirical analysis. Applied Economics, 18(5), pp.501-507.</li>
                     
                     </ul>
                     
                     <h3><b><u>Methodology</u></b></h3>
                     
                     <p><ul>
                     
                     <li>Field, A. 2005. Discovering Statistics using SPSS.</li>
                     
                     <li>Laerd Statistics. 2018. Spearman’s Rank Order Correlation. [online]. Available from: https://statistics.laerd.com/statistical-guides/spearmans-rank-order-correlation-statistical-guide.php [Accessed 12 Jan 2019].</li>
                     
                     <li>Statistics Solutions. 2018. Kendall’s Tau and Spearman’s Rank Correlation Coefficient. [online]. Available from: https://www.statisticssolutions.com/kendalls-tau-and-spearmans-rank-correlation-coefficient/ [Accessed 12 Jan 2019].</li>
                     </ul>
                     
                     <h3><b><u>Polar Chart</u></b></h3>
                     
                     <ul>
                     
                     <li>Brewer, S., Kelley, J. and Jozefowicz, J. (2009). A blueprint for success in the US film industry. Applied Economics, 41(5), pp.589-606</li></ul>
                     
                     <h3><b><u>Descriptive Analysis</u></b></h3>
                     
                     <ul>
                     
                     <li>Brownmath. (2016) Measure of Shape: Skewness and Kurtosis. Available from: https://brownmath.com/stat/shape.htm [Assessed 10 Jan 2019]</li>
                         <li>Cleveland, S. (1993) Visualizing Data. Hobart Press. At&T Bell Laboratories.</li>
                         <li>IBM Corp. (2017) IBM SPSS Statistics for Macintosh, Version 25.0. Armonk, NY: IBM Corp.</li>
                     <li>Mercer.D, Stackoverflow. 2017. How to save a seaborn plot into a file. Available from: https://stackoverflow.com/questions/32244753/how-to-save-a-seaborn-plot-into-a-file [Accessed 8 Jan 2019].</li>
                         <li>SAS Institute Inc. (1999) Distribution Analysis. SAS/ INSIGHT User’s Guide [online], 8, pp. 520-564. Available from: http://www.math.wpi.edu/saspdf/insight/chap38.pdf [Assessed 10 Jan 2019]</li>
                     <li>Sjobeek, Github. 2014. Simple way to set figsize for any plot. [online]. Available from: https://github.com/mwaskom/seaborn/issues/112 [Accessed 12 Jan 2019].</li>
                     <li>Waskom,M. 2018. Seaborn.regplot. [online]. Available from: https://seaborn.pydata.org/generated/seaborn.regplot.html [Accessed 28 Dec 2018].</li>
                     <li>Waskom,M. 2018. Controlling figure aesthetics. [online]. Available from: https://seaborn.pydata.org/tutorial/aesthetics.html [Accessed 30 Dec 2018].</li>
                     <li>Waksom,M. 2018. Seaborn.violinplot. [online]. Available from: https://seaborn.pydata.org/generated/seaborn.violinplot.html [Accessed 30 Dec 2018].</li>
                     <li>Waksom,M. 2018. Seaborn.barplot. [online]. Available from: https://seaborn.pydata.org/generated/seaborn.barplot.html [Accessed 30 Dec 2018].</li>
                     <li>Waksom,M. 2018. Seaborn.lmplot. [online]. Available from: https://seaborn.pydata.org/generated/seaborn.lmplot.html [Accessed 3 Jan 2019].</li>
                     <li>Waksom,M. 2018. Visualizing the distribution of a dataset. [online]. Available from: https://seaborn.pydata.org/tutorial/distributions.html [Accessed 15 Jan 2019].</li></ul>
                     <li>Wolfram Math World. (n.d.) Normal Distribution. Available from: http://mathworld.wolfram.com/NormalDistribution.html [Assessed 10 Jan 2019]</li>
                     <br>
                     <h3><b><u>Statistical Analysis</u></b></h3>
                     <ul>
                     
                     <li>Freedman, D.A., 2005. Statistical Models: Theory and Practice. New York: Cambridge University Press. [online] Available at http://assets.cambridge.org/052185/4830/frontmatter/0521854830_frontmatter.pdf [Accessed 5 Jan. 2019].
</li>
                         <li>Statistics Solutions. (2018). Kendall's Tau and Spearman's Rank Correlation Coefficient - Statistics Solutions. [online] Available at: https://www.statisticssolutions.com/kendalls-tau-and-spearmans-rank-correlation-coefficient/ [Accessed 5 Jan. 2019].
</li>
                         <li>Statistics Solutions. (2019). Selecting Between Parametric and Non-Parametric Analyses - Statistics Solutions. [online] Available at: https://www.statisticssolutions.com/selecting-between-parametric-and-non-parametric-analyses/ [Accessed 5 Jan. 2019].
</li>
                         <li>Statistics.laerd.com. (2019). Spearman's Rank Order Correlation using SPSS Statistics - A How-To Statistical Guide by Laerd Statistics. [online] Available at: https://statistics.laerd.com/spss-tutorials/spearmans-rank-order-correlation-using-spss-statistics.php [Accessed 5 Jan. 2019].
</li>
                         <li>Statistics.laerd.com. (2019). Kendall's Tau-b using SPSS Statistics - A How-To Statistical Guide by Laerd Statistics. [online] Available at: https://statistics.laerd.com/spss-tutorials/kendalls-tau-b-using-spss-statistics.php [Accessed 5 Jan. 2019].
</li>
                         
                         </ul>
                     
                     <h3><b><u>What the Data Tells Us</u></b></h3>
                     
                     <ul>
                     
                     <li> Cheung, K et al. 2003. Mining customer product ratings for personalized marketing. Decision Support Systems [online], 35, pp. 231-243. Available from: https://ac.els-cdn.com/S0167923602001082/1-s2.0-S0167923602001082-main.pdf?_tid=7edd3f12-ecce-4aed-a0d4-4b0de1a98213&acdnat=1547571348_104041205dda2300b4b2ef5dc63d1d1c [Accessed 14 Jan 2019].</li>
                     <li>GoodGuide. 2019. Let us guide you to what’s good. [online]. Available from: https://www.goodguide.com/#/ [Accessed 14 Jan 2019].</li>
                     <li>Hu, N; Pavlou, P & Zhang, J. 2009. Overcoming the J-shaped Distribution of Product Reviews. Technical Opinion. [online], 52(10), pp.144-147. Availble from: http://delivery.acm.org/10.1145/1570000/1562800/p144-hu.pdf?ip=144.82.8.29&id=1562800&acc=ACTIVE%20SERVICE&key=BF07A2EE685417C5%2ED93309013A15C57B%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1547571137_7ee587b02e94223be958320161059cc0 [Accessed 14 Jan 2019].</li>
                     <li>Sun, M. 2011. How Does the Variance of Product Ratings Matter? Management Science [online], 58(4), pp.iv-842. Available from: https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1110.1458 [Accessed 14 Jan 2019].</li>
                     <li>Treme, J & Craig, L. 2013. Celebrity star power: Do age and gender effects influence box office performance?. Applied Economics Letters, [online], 20(5), pp.440-445. Available from: https://www.tandfonline.com/doi/pdf/10.1080/13504851.2012.709594?needAccess=true [Accessed 14 Jan 2019].</li>
                     <li>Treme, J & Craig, L. 2013. Celebrity star power: Do age and gender effects influence box office performance?. Applied Economics Letters, [online], 20(5), pp.440-445. Available from: https://www.tandfonline.com/doi/pdf/10.1080/13504851.2012.709594?needAccess=true [Accessed 14 Jan 2019].</li>
                         <li>Women and Hollywood. 2018. 2017 Statistics: Women Onscreen. [online]. Available from: https://womenandhollywood.com/resources/statistics/2017-statistics/ [Accessed 14 Jan 2019].</li>
                     </ul>
                   
                </section>
                        

					</div>

				<!-- Footer -->
					<footer id="footer">
							<h2 align="center">Group 11:</h2>
							<p> Carlota Veal Baschwitz, Christina Jie Ying Wang, Sara Hüttl, Szymon Hawryszko, Tara Nelson  </p>
						<p class="copyright">Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
